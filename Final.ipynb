{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BlpgzcdqENEE"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfhFqloTB7R-"
      },
      "source": [
        "#Import library 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TqafCZx7Aq6"
      },
      "source": [
        "import random\n",
        "random.seed(112358)\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "\n",
        "#import the library opencv\n",
        "import cv2\n",
        "#globbing utility.\n",
        "import glob\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeRybYgpqZw5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pylab as plt \n",
        "from scipy.signal import convolve2d\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "#Some imports for getting the CIFAR-10 dataset and for help with visualization*]\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from matplotlib import cm\n",
        "from tensorflow import keras\n",
        "from keras.applications import VGG16\n",
        "\n",
        "import os\n",
        "import certifi\n",
        "import urllib3  # For handling https certificate verification \n",
        "import scipy.ndimage as ndimage\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "## Please download the packages that are missing in your colab environment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUPsPzsPjn3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5f58aa-e8ee-47df-a29f-b9ad8553a2f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJNiFdwUAUak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648199f2-3df1-4aad-9c2e-fdb3c29334ba"
      },
      "source": [
        "!unzip \"/content/drive/MyDrive/Post-hurricane.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/drive/MyDrive/Post-hurricane.zip, /content/drive/MyDrive/Post-hurricane.zip.zip or /content/drive/MyDrive/Post-hurricane.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsoqK-RrHUdm"
      },
      "source": [
        "# Loading dataset and split dataset\n",
        "In this section we load the dataset from the directory. Train dataset are stored in X_train, validation dataset are stored in X_val, and test data set are seperately stored in X_test and X_test_unbal. The if the image is loaded from undamaged, the y label will be 1, otherwise the y label will be 0. After loading the dataset, the data will be shuffled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg4mpkvHSHZc"
      },
      "source": [
        "def load_img(path1, path2):\n",
        "  path = path1\n",
        "  X_damage = np.array([np.array(cv2.imread(fname)) for fname in glob.glob(path)])\n",
        "  y_damage = np.ones(X_damage.shape[0])\n",
        "  path = path2\n",
        "  X_no_damage = np.array([np.array(cv2.imread(fname)) for fname in glob.glob(path)])\n",
        "  y_no_damage = np.zeros(X_no_damage.shape[0])\n",
        "  X = np.append(X_damage,X_no_damage,axis=0)\n",
        "  y = np.append(y_damage,y_no_damage,axis=0)\n",
        "  return shuffle(X, y, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNDgIJlGVu6P"
      },
      "source": [
        "X_train, y_train = load_img(\"train_another/damage/*.jpeg\", \"train_another/no_damage/*.jpeg\")\n",
        "X_val, y_val = load_img(\"validation_another/damage/*.jpeg\", \"validation_another/no_damage/*.jpeg\")\n",
        "X_test, y_test = load_img(\"test/damage/*.jpeg\", \"test/no_damage/*.jpeg\")\n",
        "X_test_unbal, y_test_unbal = load_img(\"test_another/damage/*.jpeg\", \"test_another/no_damage/*.jpeg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRyiieMDCicb",
        "outputId": "682b6009-48c2-4b98-b0af-9a537e57c498"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "xJaUuZX4Rch3",
        "outputId": "8721f3c6-8c86-4b80-e505-6f155d1a8c8b"
      },
      "source": [
        "fig, ax = plt.subplots(4,4)\n",
        "ax = ax.ravel()\n",
        "for i in range(16):\n",
        "  img = X_train[i]\n",
        "  ax[i].set_axis_off()\n",
        "  ax[i].imshow(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_n7JzPMDD5Ou"
      },
      "source": [
        "# VGG16 with pre_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYCKcdF6kkcy"
      },
      "source": [
        "# fit params\n",
        "nodes = 100\n",
        "input_shape = (128,128,3)\n",
        "activation = \"relu\"\n",
        "output_unit = \"sigmoid\"\n",
        "loss_fn = tf.keras.losses.binary_crossentropy\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "epochs = 8\n",
        "batch_size = 50\n",
        "validation_size = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bfZUKRXnCWq",
        "outputId": "ffe88e6e-7404-4181-99ae-65287c7cd130"
      },
      "source": [
        "con_base = VGG16(weights=\"imagenet\",include_top = False, input_shape = input_shape)\n",
        "model = Sequential()\n",
        "model.add(con_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "con_base.trainable=False\n",
        "model.summary()\n",
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n",
        "# fit each model\n",
        "#history = model.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=epochs, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               4194816   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 19,172,673\n",
            "Trainable params: 4,457,985\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7BHL6mDnM5y"
      },
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(15,6))\n",
        "ax[0].plot(history.history['accuracy'],color='#EFAEA4')\n",
        "ax[0].plot(history.history['val_accuracy'], color='#B2D7D0')\n",
        "ax[1].plot(history.history['loss'],color='#EFAEA4')\n",
        "ax[1].plot(history.history['val_loss'], color='#B2D7D0')\n",
        "ax[0].set_title('Model accuracy')\n",
        "ax[1].set_title('Model loss')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[0].legend(['Train', 'Test'], loc='best')\n",
        "ax[1].legend(['Train', 'Test'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9E5EDPhnprb"
      },
      "source": [
        "#  Bagging with VGG16 pretrain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7yC7Ug6vXdF"
      },
      "source": [
        "# VGG16 TEST MODEL\n",
        "weight_decay = 0.0005\n",
        "nb_epoch=100\n",
        "batch_size=32\n",
        "  \n",
        "#layer1 32*32*3\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "input_shape=input_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "#layer2 32*32*64\n",
        "model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#layer3 16*16*64\n",
        "model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "#layer4 16*16*128\n",
        "model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#layer5 8*8*128\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "#layer6 8*8*256\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "#layer7 8*8*256\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#layer8 4*4*256\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "#layer9 4*4*512\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "#layer10 4*4*512\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#layer11 2*2*512\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "#layer12 2*2*512\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "#layer13 2*2*512\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "#layer14 1*1*512\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "#layer15 512\n",
        "model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "#layer16 512\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "# 10\n",
        "  \n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi9HCybZwy-O",
        "outputId": "34139746-14c5-4584-c65f-a7bc707f5a5b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 128, 128, 64)      256       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128, 128, 64)      256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               4194816   \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 513       \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 19,193,665\n",
            "Trainable params: 19,183,169\n",
            "Non-trainable params: 10,496\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRhPI2h2Zk8J"
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2)\n",
        "model.fit(X_train, y_train,epochs=nb_epoch, batch_size=batch_size, validation_split=0.1, verbose=1, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXtJlNU1ct82"
      },
      "source": [
        "y_pred_unbal = model.predict(X_test_unbal)\n",
        "y_pred = model.predict(X_test)\n",
        "model.evaluate(X_test_unbal, y_test_unbal)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKAcubIJkn1n"
      },
      "source": [
        "# sampleing & data process\n",
        "# train the basic classicfier in odd number\n",
        "basic_classicfier = []\n",
        "for i in range(9):\n",
        "  # generate the basic training data of bagging, using shuffle to simulate the process\n",
        "  # of generating the random dataset which the size of it equals to the original one.\n",
        "  index = np.linspace(0,9999,10000, dtype = np.int)\n",
        "  index = shuffle(index)\n",
        "  new_X_train = []\n",
        "  new_y_train = []\n",
        "  for i in index:\n",
        "    new_X_train.append(X_train[i])\n",
        "    new_y_train.append(y_train[i])\n",
        "  new_X_train = np.array(new_X_train)\n",
        "  new_y_train = np.array(new_y_train)\n",
        "  # define each model\n",
        "  # con_base = VGG16(weights=\"imagenet\",include_top = False, input_shape = input_shape)\n",
        "  # model = Sequential()\n",
        "  # model.add(con_base)\n",
        "  # model.add(Flatten())\n",
        "  # model.add(Dense(512,activation='relu'))\n",
        "  # model.add(Dense(512,activation='relu'))\n",
        "  # model.add(Dense(1,activation='sigmoid'))\n",
        "  # con_base.trainable=False\n",
        "  # model.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n",
        "  # fit each model\n",
        "\n",
        "  # VGG16 TEST MODEL\n",
        "  weight_decay = 0.0005\n",
        "  nb_epoch=20\n",
        "  batch_size=32\n",
        "    \n",
        "  #layer1 32*32*3\n",
        "  model_vgg = Sequential()\n",
        "  model_vgg.add(Conv2D(64, (3, 3), padding='same',\n",
        "  input_shape=input_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model_vgg.add(Activation('relu'))\n",
        "  model_vgg.add(BatchNormalization())\n",
        "  model_vgg.add(Dropout(0.3))\n",
        "  #layer2 32*32*64\n",
        "  model_vgg.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model_vgg.add(Activation('relu'))\n",
        "  model_vgg.add(BatchNormalization())\n",
        "  model_vgg.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  #layer3 16*16*64\n",
        "  model_vgg.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model_vgg.add(Activation('relu'))\n",
        "  model_vgg.add(BatchNormalization())\n",
        "  model_vgg.add(Dropout(0.4))\n",
        "  #layer4 16*16*128\n",
        "  model_vgg.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model_vgg.add(Activation('relu'))\n",
        "  model_vgg.add(BatchNormalization())\n",
        "  model_vgg.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  #layer5 8*8*128\n",
        "  model_vgg.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model_vgg.add(Activation('relu'))\n",
        "  model_vgg.add(BatchNormalization())\n",
        "  model_vgg.add(Dropout(0.4))\n",
        "  #layer6 8*8*256\n",
        "  model_vgg.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model_vgg.add(Activation('relu'))\n",
        "  model_vgg.add(BatchNormalization())\n",
        "  model_vgg.add(Dropout(0.4))\n",
        "  #layer7 8*8*256\n",
        "  model_vgg.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model_vgg.add(Activation('relu'))\n",
        "  model_vgg.add(BatchNormalization())\n",
        "  model_vgg.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  #layer8 4*4*256\n",
        "  model_vgg.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model_vgg.add(Activation('relu'))\n",
        "  model_vgg.add(BatchNormalization())\n",
        "  model_vgg.add(Dropout(0.4))\n",
        "  #layer9 4*4*512\n",
        "  model_vgg.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model_vgg.add(Activation('relu'))\n",
        "  model_vgg.add(BatchNormalization())\n",
        "  model_vgg.add(Dropout(0.4))\n",
        "  #layer10 4*4*512\n",
        "  model_vgg.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model_vgg.add(Activation('relu'))\n",
        "  model_vgg.add(BatchNormalization())\n",
        "  model_vgg.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  #layer11 2*2*512\n",
        "  model_vgg.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model_vgg.add(Activation('relu'))\n",
        "  model_vgg.add(BatchNormalization())\n",
        "  model_vgg.add(Dropout(0.4))\n",
        "  #layer12 2*2*512\n",
        "  model_vgg.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model_vgg.add(Activation('relu'))\n",
        "  model_vgg.add(BatchNormalization())\n",
        "  model_vgg.add(Dropout(0.4))\n",
        "  #layer13 2*2*512\n",
        "  model_vgg.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model_vgg.add(Activation('relu'))\n",
        "  model_vgg.add(BatchNormalization())\n",
        "  model_vgg.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model_vgg.add(Dropout(0.5))\n",
        "  #layer14 1*1*512\n",
        "  model_vgg.add(Flatten())\n",
        "  model_vgg.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model_vgg.add(Activation('relu'))\n",
        "  model_vgg.add(BatchNormalization())\n",
        "  #layer15 512\n",
        "  model_vgg.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model_vgg.add(Activation('relu'))\n",
        "  model_vgg.add(BatchNormalization())\n",
        "  #layer16 512\n",
        "  model_vgg.add(Dropout(0.5))\n",
        "  model_vgg.add(Dense(1))\n",
        "  model_vgg.add(Activation('sigmoid'))\n",
        "  # 10\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2)\n",
        "\n",
        "  model_vgg.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
        "  model_vgg.fit(new_X_train, new_y_train, epochs=nb_epoch, batch_size=batch_size, x=0.2, verbose=1, callbacks=[early_stopping])\n",
        "\n",
        "  print(X_train[0].shape)\n",
        "  basic_classicfier.append(model_vgg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUgP_6Zxk4Nn"
      },
      "source": [
        "# the process of bagging\n",
        "# fit each model using the original data\n",
        "res_pre = []\n",
        "for w in basic_classicfier:\n",
        "  pre_res = w.predict_classes(X_test)\n",
        "  res_pre.append(pre_res)\n",
        "# the process of voting\n",
        "right_count = 0\n",
        "new_res = []\n",
        "# presicion and recall\n",
        "tp = 0\n",
        "fp = 0\n",
        "tn = 0\n",
        "fn = 0\n",
        "for i in range(2000):\n",
        "  res_tmp = []\n",
        "  for item in res_pre:\n",
        "    res_tmp.append(item[i])\n",
        "  res_val_0 = res_tmp.count(0)\n",
        "  res_val_1 = res_tmp.count(1)\n",
        "  if res_val_0 > res_val_1:\n",
        "    res_val = 0\n",
        "  else:\n",
        "    res_val = 1\n",
        "  new_res.append(res_val)\n",
        "  if res_val == y_test[i]:\n",
        "    right_count += 1\n",
        "    if res_val == 1:\n",
        "      tp += 1\n",
        "    if res_val == 0:\n",
        "      tn += 1\n",
        "  else:\n",
        "    if res_val == 1:\n",
        "      fp += 1\n",
        "    if res_val == 0:\n",
        "      fn += 1\n",
        "recall = tp/(tp+fn)\n",
        "precise = tp/(tp+fp)\n",
        "bagging_accuracy = right_count/2000*100\n",
        "print(\"accuracy: \" + str(bagging_accuracy) + \"%\")\n",
        "print(\"recall: \" + str(recall) + \"%\")\n",
        "print(\"precise: \" + str(precise) + \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssPc-ZJxQYzV"
      },
      "source": [
        "# the process of bagging\n",
        "# fit each model using the original data\n",
        "res_pre = []\n",
        "for w in basic_classicfier:\n",
        "  pre_res = w.predict_classes(X_test_unbal)\n",
        "  res_pre.append(pre_res)\n",
        "# the process of voting\n",
        "right_count = 0\n",
        "new_res = []\n",
        "# presicion and recall\n",
        "tp = 0\n",
        "fp = 0\n",
        "tn = 0\n",
        "fn = 0\n",
        "for i in range(2000):\n",
        "  res_tmp = []\n",
        "  for item in res_pre:\n",
        "    res_tmp.append(item[i])\n",
        "  res_val_0 = res_tmp.count(0)\n",
        "  res_val_1 = res_tmp.count(1)\n",
        "  if res_val_0 > res_val_1:\n",
        "    res_val = 0\n",
        "  else:\n",
        "    res_val = 1\n",
        "  new_res.append(res_val)\n",
        "  if res_val == y_test_unbal[i]:\n",
        "    right_count += 1\n",
        "    if res_val == 1:\n",
        "      tp += 1\n",
        "    if res_val == 0:\n",
        "      tn += 1\n",
        "  else:\n",
        "    if res_val == 1:\n",
        "      fp += 1\n",
        "    if res_val == 0:\n",
        "      fn += 1\n",
        "recall = tp/(tp+fn)\n",
        "precise = tp/(tp+fp)\n",
        "bagging_accuracy = right_count/2000*100\n",
        "print(\"accuracy: \" + str(bagging_accuracy) + \"%\")\n",
        "print(\"recall: \" + str(recall) + \"%\")\n",
        "print(\"precise: \" + str(precise) + \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr4wRrj5VM-_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzdI_So4lJfX"
      },
      "source": [
        "con_base = VGG16(weights=\"imagenet\",include_top=False, input_shape= input_shape)\n",
        "model4 = Sequential()\n",
        "model4.add(con_base)\n",
        "model4.add(Flatten())\n",
        "model4.add(Dense(512,activation='relu'))\n",
        "model4.add(Dense(512,activation='relu'))\n",
        "model4.add(Dense(1,activation='sigmoid'))\n",
        "con_base.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww75mz1dlRl7"
      },
      "source": [
        "model4.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_fn,\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model4.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZyzHX6BlT3R"
      },
      "source": [
        "history4 = model4.fit(    \n",
        "    X_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=epochs, \n",
        "    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jj8TRpJlg7o"
      },
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(15,6))\n",
        "ax[0].plot(history4.history['accuracy'],color='#EFAEA4')\n",
        "ax[0].plot(history4.history['val_accuracy'], color='#B2D7D0')\n",
        "ax[1].plot(history4.history['loss'],color='#EFAEA4')\n",
        "ax[1].plot(history4.history['val_loss'], color='#B2D7D0')\n",
        "ax[0].set_title('Model accuracy')\n",
        "ax[1].set_title('Model loss')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[0].legend(['Train', 'Test'], loc='best')\n",
        "ax[1].legend(['Train', 'Test'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KDyMD77wweT"
      },
      "source": [
        "y_pred_unbal = model4.predict(X_test_unbal)\n",
        "y_pred = model4.predict(X_test)\n",
        "model4.evaluate(X_test_unbal, y_test_unbal)\n",
        "model4.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlpgzcdqENEE"
      },
      "source": [
        "# Basic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cv1TNV9lryt"
      },
      "source": [
        "model1 = tf.keras.models.Sequential(\n",
        "    [\n",
        "      Input(shape = input_shape),\n",
        "      Conv2D(32, 3, strides = (1,1), padding = \"same\", activation=\"relu\"),\n",
        "      Conv2D(32, 3, strides = (1,1), activation=\"relu\"),\n",
        "      MaxPooling2D(pool_size = (2,2), strides = 2),\n",
        "      Conv2D(64, 3, strides = (1,1), padding = \"same\", activation=\"relu\"),\n",
        "      Conv2D(64, 3, strides = (1,1), activation=\"relu\"),\n",
        "      MaxPooling2D(pool_size = (2,2), strides = 2),\n",
        "      Flatten(),\n",
        "      Dense(128, activation = \"relu\"),\n",
        "      Dropout(0.2),\n",
        "      Dense(32, activation = \"relu\"),\n",
        "      Dense(1, activation = \"sigmoid\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "model1.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss_fn,\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V10eB-l9luW8"
      },
      "source": [
        "history = model1.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=epochs, \n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ushy1zufHf7R"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5RPrekXEUAy"
      },
      "source": [
        "# Alexnet "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AWO49hJDAKw"
      },
      "source": [
        "# fit params\n",
        "nodes = 100\n",
        "input_shape = (128,128,3)\n",
        "activation = \"relu\"\n",
        "output_unit = \"sigmoid\"\n",
        "loss_fn = tf.keras.losses.binary_crossentropy\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "epochs = 8\n",
        "batch_size = 50\n",
        "validation_size = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClY8whU-lwlQ"
      },
      "source": [
        "# fit params\n",
        "nodes = 100\n",
        "input_shape = (128,128,3)\n",
        "activation = \"relu\"\n",
        "output_unit = \"sigmoid\"\n",
        "loss_fn = tf.keras.losses.binary_crossentropy\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "epochs = 8\n",
        "batch_size = 50\n",
        "validation_size = 0.3\n",
        "\n",
        "model_alexnet = Sequential()  \n",
        "model_alexnet.add(Conv2D(96,(11,11),strides=(4,4),input_shape=input_shape,padding='valid',activation='relu',kernel_initializer='uniform'))  \n",
        "model_alexnet.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))  \n",
        "model_alexnet.add(Conv2D(256,(5,5),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
        "model_alexnet.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))  \n",
        "model_alexnet.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
        "model_alexnet.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
        "model_alexnet.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
        "model_alexnet.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))  \n",
        "model_alexnet.add(Flatten())  \n",
        "model_alexnet.add(Dense(4096,activation='relu'))  \n",
        "model_alexnet.add(Dropout(0.5))  \n",
        "model_alexnet.add(Dense(4096,activation='relu'))  \n",
        "model_alexnet.add(Dropout(0.5))  \n",
        "model_alexnet.add(Dense(1,activation='sigmoid'))  \n",
        "\n",
        "model_alexnet.compile(loss=keras.losses.binary_crossentropy,optimizer= 'adam',metrics=['accuracy'])  \n",
        "model_alexnet.summary()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVN_2AGve1Sg"
      },
      "source": [
        "model_alexnet_1 = Sequential()  \n",
        "model_alexnet_1.add(Conv2D(96,(5,5),strides=(4,4),input_shape=input_shape,padding='valid',activation='relu',kernel_initializer='uniform'))  \n",
        "model_alexnet_1.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))  \n",
        "model_alexnet_1.add(Conv2D(256,(5,5),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
        "model_alexnet_1.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))  \n",
        "model_alexnet_1.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
        "model_alexnet_1.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
        "model_alexnet_1.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
        "model_alexnet_1.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))  \n",
        "model_alexnet_1.add(Flatten())  \n",
        "model_alexnet_1.add(Dense(1024,activation='relu'))  \n",
        "model_alexnet_1.add(Dropout(0.5))  \n",
        "model_alexnet_1.add(Dense(1024,activation='relu'))  \n",
        "model_alexnet_1.add(Dropout(0.5))  \n",
        "model_alexnet_1.add(Dense(1,activation='sigmoid'))  \n",
        "sgd = keras.optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n",
        "model_alexnet_1.compile(loss=keras.losses.binary_crossentropy,optimizer= 'adam',metrics=['accuracy'])  \n",
        "model_alexnet_1.summary()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnhhtABAe7Ce"
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2)\n",
        "model_alexnet_1.fit(X_train, y_train,epochs=20, batch_size=batch_size, validation_split=0.2, verbose=1, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fONwZrjJRlB0"
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2)\n",
        "model_alexnet.fit(X_train, y_train,epochs=20, batch_size=batch_size, validation_split=0.2, verbose=1, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na0x61-lPbAj"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6jNHkNklzyF"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=epochs, \n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTJxqzy4PdR4"
      },
      "source": [
        "y_pred_unbal = model.predict(X_test_unbal)\n",
        "y_pred = model.predict(X_test)\n",
        "model.evaluate(X_test_unbal, y_test_unbal)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrYfMROCEbeq"
      },
      "source": [
        "# Model A"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bztv0gnIl2c2"
      },
      "source": [
        "model2=Sequential()\n",
        "model2.add(Conv2D(64,((2,2)),padding='same',input_shape=input_shape,activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Conv2D(64,((2,2)),padding='same',activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPooling2D((2,2),strides=2))\n",
        " \n",
        "model2.add(Conv2D(128,((2,2)),padding='same',activation='relu'))\n",
        "model2.add(Conv2D(128,((2,2)),padding='same',activation='relu'))\n",
        "model2.add(MaxPooling2D((2,2),strides=2))\n",
        " \n",
        "model2.add(Conv2D(64,(1,1),padding='same',activation='relu'))\n",
        "model2.add(Conv2D(64,(1,1),padding='same',activation='relu'))\n",
        "model2.add(MaxPooling2D((2,2),strides=2))\n",
        " \n",
        "model2.add(Conv2D(128,(1,1),padding='same',activation='relu'))\n",
        "model2.add(Conv2D(128,(1,1),padding='same',activation='relu'))\n",
        "model2.add(Conv2D(128,(1,1),padding='same',activation='relu'))\n",
        "model2.add(Conv2D(128,(1,1),padding='same',activation='relu'))\n",
        "model2.add(MaxPooling2D((2,2),strides=2))\n",
        " \n",
        "model2.add(Conv2D(32,(1,1),padding='same',activation='relu'))\n",
        "model2.add(Conv2D(32,(1,1),padding='same',activation='relu'))\n",
        "model2.add(Conv2D(32,(1,1),padding='same',activation='relu'))\n",
        "model2.add(Conv2D(32,(1,1),padding='same',activation='relu'))\n",
        "model2.add(MaxPooling2D((2,2),strides=2))\n",
        " \n",
        "model2.add(Flatten())\n",
        "# model2.add(Dense(1024,activation='relu'))\n",
        "model2.add(Dense(512,activation='relu'))\n",
        "model2.add(Dense(512,activation='relu'))\n",
        "model2.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model2.compile(optimizer= optimizer,\n",
        "              loss= keras.losses.binary_crossentropy,\n",
        "              metrics= ['accuracy'])\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K0s7cz0l5uo"
      },
      "source": [
        "# VGG16\n",
        "history = model2.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=epochs, \n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHc1Qu6Ml7pe"
      },
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(15,6))\n",
        "ax[0].plot(history.history['accuracy'],color='#EFAEA4')\n",
        "ax[0].plot(history.history['val_accuracy'], color='#B2D7D0')\n",
        "ax[1].plot(history.history['loss'],color='#EFAEA4')\n",
        "ax[1].plot(history.history['val_loss'], color='#B2D7D0')\n",
        "ax[0].set_title('Model accuracy')\n",
        "ax[1].set_title('Model loss')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[0].legend(['Train', 'Test'], loc='best')\n",
        "ax[1].legend(['Train', 'Test'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLTrGYX4l9vw"
      },
      "source": [
        "y_pred_unbal = model2.predict(X_test_unbal)\n",
        "y_pred = model2.predict(X_test)\n",
        "model2.evaluate(X_test_unbal, y_test_unbal)\n",
        "model2.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6nhxL6Zxy8Q"
      },
      "source": [
        "num = 15\n",
        "model.evaluate(X_test_unbal[num].reshape(-1,128,128,3), y_test_unbal[num].reshape(-1,1))\n",
        "y_test_unbal[num].reshape(-1,1),model.predict(X_test_unbal[num].reshape(-1,128,128,3))\n",
        "# fig, ax = plt.subplots(1,1)\n",
        "# ax.imshow(X_test_unbal[num])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6rb9ajJr5D4"
      },
      "source": [
        "# Resnet with pre-train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f5C0nvWxPs-"
      },
      "source": [
        "# fit params\n",
        "nodes = 100\n",
        "input_shape = (128,128,3)\n",
        "activation = \"relu\"\n",
        "output_unit = \"sigmoid\"\n",
        "loss_fn = tf.keras.losses.binary_crossentropy\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "epochs = 8\n",
        "batch_size = 50\n",
        "validation_size = 0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqlhBZ7lsLf-"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "con_base5 = ResNet50(weights='imagenet', include_top = False, input_shape = input_shape)\n",
        "model5 = Sequential()\n",
        "model5.add(con_base5)\n",
        "model5.add(Flatten())\n",
        "model5.add(Dense(512,activation='relu'))\n",
        "model5.add(Dropout(0.4))\n",
        "model5.add(Dense(512,activation='relu'))\n",
        "model5.add(Dropout(0.3))\n",
        "model5.add(Dense(1,activation='sigmoid'))\n",
        "con_base5.trainable=False\n",
        "model5.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n",
        "# fit each model\n",
        "history = model5.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=epochs, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCCyVDiLxUC4"
      },
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(15,6))\n",
        "ax[0].plot(history.history['accuracy'],color='#EFAEA4')\n",
        "ax[0].plot(history.history['val_accuracy'], color='#B2D7D0')\n",
        "ax[1].plot(history.history['loss'],color='#EFAEA4')\n",
        "ax[1].plot(history.history['val_loss'], color='#B2D7D0')\n",
        "ax[0].set_title('Model accuracy')\n",
        "ax[1].set_title('Model loss')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[0].legend(['Train', 'Test'], loc='best')\n",
        "ax[1].legend(['Train', 'Test'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAtyr5mZqii7"
      },
      "source": [
        "# Xception with pre_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT5kngpNuC-i"
      },
      "source": [
        "from tensorflow.keras.applications.xception import Xception\n",
        "\n",
        "input_shape = (128,128,3)\n",
        "loss_fn = tf.keras.losses.binary_crossentropy\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "epochs = 8\n",
        "batch_size = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ_1DgVG9yYg"
      },
      "source": [
        "# sampleing & data process\n",
        "# train the basic classicfier in odd number\n",
        "basic_classicfier = []\n",
        "for i in range(9):\n",
        "  # generate the basic training data of bagging, using shuffle to simulate the process\n",
        "  # of generating the random dataset which the size of it equals to the original one.\n",
        "  index = np.linspace(0,9999,10000, dtype = np.int)\n",
        "  index = shuffle(index)\n",
        "  new_X_train = []\n",
        "  new_y_train = []\n",
        "  for i in index:\n",
        "    new_X_train.append(X_train[i])\n",
        "    new_y_train.append(y_train[i])\n",
        "  new_X_train = np.array(new_X_train)\n",
        "  new_y_train = np.array(new_y_train)\n",
        "\n",
        "  con_base_Xcep = Xception(weights='imagenet', include_top = False, input_shape = input_shape)\n",
        "  model_Xcep = Sequential()\n",
        "  model_Xcep.add(con_base_Xcep)\n",
        "  model_Xcep.add(Flatten())\n",
        "  model_Xcep.add(Dense(512,activation='relu'))\n",
        "  model_Xcep.add(Dense(512,activation='relu'))\n",
        "  model_Xcep.add(Dense(1,activation='sigmoid'))\n",
        "  con_base_Xcep.trainable=False\n",
        "  model_Xcep.compile(optimizer=optimizer, loss=loss_fn, metrics=[\"accuracy\"])\n",
        "  # fit each model\n",
        "  history_Xcep = model_Xcep.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=epochs, verbose=1)\n",
        "\n",
        "  basic_classicfier.append(model_Xcep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBXxAOku-t_L"
      },
      "source": [
        "# the process of bagging\n",
        "# fit each model using the original data\n",
        "res_pre = []\n",
        "for w in basic_classicfier:\n",
        "  pre_res = w.predict_classes(X_test_unbal)\n",
        "  res_pre.append(pre_res)\n",
        "# the process of voting\n",
        "right_count = 0\n",
        "new_res = []\n",
        "# presicion and recall\n",
        "tp = 0\n",
        "fp = 0\n",
        "tn = 0\n",
        "fn = 0\n",
        "for i in range(2000):\n",
        "  res_tmp = []\n",
        "  for item in res_pre:\n",
        "    res_tmp.append(item[i])\n",
        "  res_val_0 = res_tmp.count(0)\n",
        "  res_val_1 = res_tmp.count(1)\n",
        "  if res_val_0 > res_val_1:\n",
        "    res_val = 0\n",
        "  else:\n",
        "    res_val = 1\n",
        "  new_res.append(res_val)\n",
        "  if res_val == y_test_unbal[i]:\n",
        "    right_count += 1\n",
        "    if res_val == 1:\n",
        "      tp += 1\n",
        "    if res_val == 0:\n",
        "      tn += 1\n",
        "  else:\n",
        "    if res_val == 1:\n",
        "      fp += 1\n",
        "    if res_val == 0:\n",
        "      fn += 1\n",
        "recall = tp/(tp+fn)\n",
        "precise = tp/(tp+fp)\n",
        "bagging_accuracy = right_count/2000*100\n",
        "print(\"accuracy: \" + str(bagging_accuracy) + \"%\")\n",
        "print(\"recall: \" + str(recall) + \"%\")\n",
        "print(\"precise: \" + str(precise) + \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XAgTs5VzMBE"
      },
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(15,6))\n",
        "ax[0].plot(history.history['accuracy'],color='#EFAEA4')\n",
        "ax[0].plot(history.history['val_accuracy'], color='#B2D7D0')\n",
        "ax[1].plot(history.history['loss'],color='#EFAEA4')\n",
        "ax[1].plot(history.history['val_loss'], color='#B2D7D0')\n",
        "ax[0].set_title('Model accuracy')\n",
        "ax[1].set_title('Model loss')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[0].legend(['Train', 'Test'], loc='best')\n",
        "ax[1].legend(['Train', 'Test'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca2kdp2Sd8Tp"
      },
      "source": [
        "# Xception Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfjBnUHNeDuU"
      },
      "source": [
        "import os  \n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Conv2D, Dense, BatchNormalization, Activation\n",
        "from keras.layers import GlobalAveragePooling2D, MaxPooling2D, add\n",
        "from keras.models import Model\n",
        "from keras.layers import SeparableConv2D\n",
        "\n",
        "from keras import optimizers,regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.initializers import he_normal\n",
        "from keras.callbacks import LearningRateScheduler, TensorBoard, ModelCheckpoint\n",
        "\n",
        "batch_size         = 32         # 64 or 32 or other\n",
        "epochs             = 8\n",
        "\n",
        "# 36 convolutional layers are structured into 14 modules\n",
        "def entryflow(x,params,top=False):\n",
        "    # modules 2-4,13\n",
        "    # params is (3,)\n",
        "    # top = true means module 2, don't use relu\n",
        "    residual = Conv2D(params[0], (1, 1), strides=(2, 2),padding='same')(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "    if top:\n",
        "        x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params[1], (3, 3),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params[2], (3, 3),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2),padding='same')(x)\n",
        "    x = add([x, residual])\n",
        "    return x\n",
        "\n",
        "def middleflow(x,params):\n",
        "    # modules 5-12, params is int\n",
        "    residual = x\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params, (3, 3),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params, (3, 3),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params, (3, 3),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = add([x, residual])\n",
        "    return x\n",
        "\n",
        "def exitflow(x,params):\n",
        "    # modules 14 , params is (2,)\n",
        "    x = SeparableConv2D(params[0], (3, 3),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params[1], (3, 3),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)   \n",
        "    return x\n",
        "\n",
        "def xception(img_input,shallow=False, classes=1):\n",
        "    # modules 1\n",
        "    x = Conv2D(32,(3, 3),strides=(2, 2),padding='same')(img_input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64, (3, 3),strides=(1,1),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    # module 2\n",
        "    x = entryflow(x,(128,128,128),top=True)\n",
        "    # module 3-4\n",
        "    x = entryflow(x,(256,256,256))\n",
        "    x = entryflow(x,(728,728,728))\n",
        "    # module 5-12\n",
        "    for _ in range(8):\n",
        "        x = middleflow(x,728)\n",
        "    # module 13\n",
        "    x = entryflow(x,(1024,728,1024))\n",
        "    # module 14\n",
        "    x = exitflow(x,(1536,2048))\n",
        "    # output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(classes, activation='softmax')(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv6CL5DBeJ2q"
      },
      "source": [
        "img_input=Input(shape=(128,128,3))\n",
        "output = xception(img_input)\n",
        "model_Xcep=Model(img_input,output)\n",
        "model_Xcep.summary()\n",
        "model_Xcep.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RH7Z9MTed6T"
      },
      "source": [
        "# sampleing & data process\n",
        "# train the basic classicfier in odd number\n",
        "basic_classicfier = []\n",
        "for i in range(9):\n",
        "  # generate the basic training data of bagging, using shuffle to simulate the process\n",
        "  # of generating the random dataset which the size of it equals to the original one.\n",
        "  index = np.linspace(0,9999,10000, dtype = np.int)\n",
        "  index = shuffle(index)\n",
        "  new_X_train = []\n",
        "  new_y_train = []\n",
        "  for i in index:\n",
        "    new_X_train.append(X_train[i])\n",
        "    new_y_train.append(y_train[i])\n",
        "  new_X_train = np.array(new_X_train)\n",
        "  new_y_train = np.array(new_y_train)\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2)\n",
        "\n",
        "  # fit each model\n",
        "  history_Xcep = model_Xcep.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=epochs, verbose=1, callbacks=early_stopping)\n",
        "\n",
        "  basic_classicfier.append(model_Xcep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-VhV875e4ut"
      },
      "source": [
        "# the process of bagging\n",
        "# fit each model using the original data\n",
        "res_pre = []\n",
        "for w in basic_classicfier:\n",
        "  pre_res = w.predict_classes(X_test_unbal)\n",
        "  res_pre.append(pre_res)\n",
        "# the process of voting\n",
        "right_count = 0\n",
        "new_res = []\n",
        "# presicion and recall\n",
        "tp = 0\n",
        "fp = 0\n",
        "tn = 0\n",
        "fn = 0\n",
        "for i in range(2000):\n",
        "  res_tmp = []\n",
        "  for item in res_pre:\n",
        "    res_tmp.append(item[i])\n",
        "  res_val_0 = res_tmp.count(0)\n",
        "  res_val_1 = res_tmp.count(1)\n",
        "  if res_val_0 > res_val_1:\n",
        "    res_val = 0\n",
        "  else:\n",
        "    res_val = 1\n",
        "  new_res.append(res_val)\n",
        "  if res_val == y_test_unbal[i]:\n",
        "    right_count += 1\n",
        "    if res_val == 1:\n",
        "      tp += 1\n",
        "    if res_val == 0:\n",
        "      tn += 1\n",
        "  else:\n",
        "    if res_val == 1:\n",
        "      fp += 1\n",
        "    if res_val == 0:\n",
        "      fn += 1\n",
        "recall = tp/(tp+fn)\n",
        "precise = tp/(tp+fp)\n",
        "bagging_accuracy = right_count/2000*100\n",
        "print(\"accuracy: \" + str(bagging_accuracy) + \"%\")\n",
        "print(\"recall: \" + str(recall) + \"%\")\n",
        "print(\"precise: \" + str(precise) + \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU4Jxoqre_jb"
      },
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(15,6))\n",
        "ax[0].plot(history.history['accuracy'],color='#EFAEA4')\n",
        "ax[0].plot(history.history['val_accuracy'], color='#B2D7D0')\n",
        "ax[1].plot(history.history['loss'],color='#EFAEA4')\n",
        "ax[1].plot(history.history['val_loss'], color='#B2D7D0')\n",
        "ax[0].set_title('Model accuracy')\n",
        "ax[1].set_title('Model loss')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[0].legend(['Train', 'Test'], loc='best')\n",
        "ax[1].legend(['Train', 'Test'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuRHWPZ_uMPH"
      },
      "source": [
        "# Simple Xception Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXNjTV1XuZav"
      },
      "source": [
        "import os  \n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Conv2D, Dense, BatchNormalization, Activation\n",
        "from keras.layers import GlobalAveragePooling2D, MaxPooling2D, add\n",
        "from keras.models import Model\n",
        "from keras.layers import SeparableConv2D\n",
        "\n",
        "from keras import optimizers,regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.initializers import he_normal\n",
        "from keras.callbacks import LearningRateScheduler, TensorBoard, ModelCheckpoint\n",
        "\n",
        "batch_size         = 32         # 64 or 32 or other\n",
        "epochs             = 8\n",
        "\n",
        "# 36 convolutional layers are structured into 14 modules\n",
        "def entryflow(x,params,top=False):\n",
        "    # modules 2-4,13\n",
        "    # params is (3,)\n",
        "    # top = true means module 2, don't use relu\n",
        "    residual = Conv2D(params[0], (1, 1), strides=(2, 2),padding='same')(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "    if top:\n",
        "        x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params[1], (2, 2),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params[2], (2, 2),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2),padding='same')(x)\n",
        "    x = add([x, residual])\n",
        "    return x\n",
        "\n",
        "def middleflow(x,params):\n",
        "    # modules 5-12, params is int\n",
        "    residual = x\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params, (2, 2),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params, (2, 2),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params, (2, 2),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = add([x, residual])\n",
        "    return x\n",
        "\n",
        "def exitflow(x,params):\n",
        "    # modules 14 , params is (2,)\n",
        "    x = SeparableConv2D(params[0], (2, 2),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params[1], (2, 2),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)   \n",
        "    return x\n",
        "\n",
        "def xception(img_input,shallow=False, classes=1):\n",
        "    # modules 1\n",
        "    x = Conv2D(32,(2, 2),strides=(2, 2),padding='same')(img_input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64, (2, 2),strides=(1,1),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    # module 2\n",
        "    x = entryflow(x,(32,32,32),top=True)\n",
        "    # module 3-4\n",
        "    x = entryflow(x,(32,32,32))\n",
        "    x = entryflow(x,(32,32,32))\n",
        "    # module 5-12\n",
        "    for _ in range(8):\n",
        "        x = middleflow(x,32)\n",
        "    # module 13\n",
        "    x = entryflow(x,(128,128,128))\n",
        "    # module 14\n",
        "    x = exitflow(x,(128,128))\n",
        "    # output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(classes, activation='sigmoid')(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nb5dKjludVz"
      },
      "source": [
        "img_input=Input(shape=(128,128,3))\n",
        "output = xception(img_input)\n",
        "model_Xcep=Model(img_input,output)\n",
        "model_Xcep.summary()\n",
        "\n",
        "model_Xcep.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH1FNxeaukqL"
      },
      "source": [
        "# sampleing & data process\n",
        "# train the basic classicfier in odd number\n",
        "basic_classicfier = []\n",
        "for i in range(9):\n",
        "  # generate the basic training data of bagging, using shuffle to simulate the process\n",
        "  # of generating the random dataset which the size of it equals to the original one.\n",
        "  index = np.linspace(0,9999,10000, dtype = np.int)\n",
        "  index = shuffle(index)\n",
        "  new_X_train = []\n",
        "  new_y_train = []\n",
        "  for i in index:\n",
        "    new_X_train.append(X_train[i])\n",
        "    new_y_train.append(y_train[i])\n",
        "  new_X_train = np.array(new_X_train)\n",
        "  new_y_train = np.array(new_y_train)\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=2)\n",
        "\n",
        "  # fit each model\n",
        "  history_Xcep = model_Xcep.fit(X_train, y_train, batch_size=batch_size, validation_data=(X_val, y_val), epochs=epochs, verbose=1, callbacks=early_stopping)\n",
        "\n",
        "  basic_classicfier.append(model_Xcep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwed1_CtulYj"
      },
      "source": [
        "# the process of bagging\n",
        "# fit each model using the original data\n",
        "res_pre = []\n",
        "for w in basic_classicfier:\n",
        "  pre_res = model_Xcep.predict(X_test_unbal)\n",
        "  res_pre.append(pre_res)\n",
        "# the process of voting\n",
        "right_count = 0\n",
        "new_res = []\n",
        "# presicion and recall\n",
        "tp = 0\n",
        "fp = 0\n",
        "tn = 0\n",
        "fn = 0\n",
        "for i in range(2000):\n",
        "  res_tmp = []\n",
        "  for item in res_pre:\n",
        "    res_tmp.append(item[i])\n",
        "  res_val_0 = res_tmp.count(0)\n",
        "  res_val_1 = res_tmp.count(1)\n",
        "  if res_val_0 > res_val_1:\n",
        "    res_val = 0\n",
        "  else:\n",
        "    res_val = 1\n",
        "  new_res.append(res_val)\n",
        "  if res_val == y_test_unbal[i]:\n",
        "    right_count += 1\n",
        "    if res_val == 1:\n",
        "      tp += 1\n",
        "    if res_val == 0:\n",
        "      tn += 1\n",
        "  else:\n",
        "    if res_val == 1:\n",
        "      fp += 1\n",
        "    if res_val == 0:\n",
        "      fn += 1\n",
        "recall = tp/(tp+fn)\n",
        "precise = tp/(tp+fp)\n",
        "bagging_accuracy = right_count/2000*100\n",
        "print(\"accuracy: \" + str(bagging_accuracy) + \"%\")\n",
        "print(\"recall: \" + str(recall) + \"%\")\n",
        "print(\"precise: \" + str(precise) + \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auSDmjPzupP0"
      },
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(15,6))\n",
        "ax[0].plot(history_Xcep.history['accuracy'],color='#EFAEA4')\n",
        "ax[0].plot(history_Xcep.history['val_accuracy'], color='#B2D7D0')\n",
        "ax[1].plot(history_Xcep.history['loss'],color='#EFAEA4')\n",
        "ax[1].plot(history_Xcep.history['val_loss'], color='#B2D7D0')\n",
        "ax[0].set_title('Model accuracy')\n",
        "ax[1].set_title('Model loss')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[0].legend(['Train', 'Test'], loc='best')\n",
        "ax[1].legend(['Train', 'Test'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzO6ntJZ0GXJ"
      },
      "source": [
        "# Occlusion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHhGNpag-977"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkm4uHVs0LB4"
      },
      "source": [
        "# Create function to apply a grey patch on an image\n",
        "def apply_grey_patch(image, top_left_x, top_left_y, patch_size):\n",
        "    patched_image = np.array(image, copy=True)\n",
        "    patched_image[top_left_y:top_left_y + patch_size, top_left_x:top_left_x + patch_size, :] = 127\n",
        "    # patched_image[top_left_y:top_left_y + patch_size, top_left_x:top_left_x + patch_size, 0] = image[:,:,0].mean()\n",
        "    # patched_image[top_left_y:top_left_y + patch_size, top_left_x:top_left_x + patch_size, 1] = image[:,:,1].mean()\n",
        "    # patched_image[top_left_y:top_left_y + patch_size, top_left_x:top_left_x + patch_size, 2] = image[:,:,2].mean()\n",
        "    return patched_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzFWj6Af6yk3"
      },
      "source": [
        "def load_dataset():\n",
        "\t\n",
        "\t#load dataframe\n",
        "  path = \"train_another/damage/*.jpeg\"\n",
        "  X_damage_df = np.array([np.array(fname) for fname in glob.glob(path)])\n",
        "  y_damage_df = np.ones(X_damage_df.shape[0]).astype(int).astype(str)\n",
        "  path = \"train_another/no_damage/*.jpeg\"\n",
        "  X_no_damage_df = np.array([np.array(fname) for fname in glob.glob(path)])\n",
        "  y_no_damage_df = np.zeros(X_no_damage_df.shape[0]).astype(int).astype(str)\n",
        "  X_df = np.append(X_damage_df,X_no_damage_df,axis=0)\n",
        "  y_df = np.append(y_damage_df,y_no_damage_df,axis=0)\n",
        "  X_df, y_df = shuffle(X_df, y_df, random_state = 0)\n",
        "  df = pd.DataFrame({\"image\":X_df,\"label\":y_df})\n",
        "  \n",
        "  generator = ImageDataGenerator(rescale=1./255)\n",
        "  \n",
        "  data_gen = generator.flow_from_dataframe(\n",
        "    df, directory=None, x_col='image', y_col='label',\n",
        "    target_size=(128,128), color_mode='rgb', seed=30,\n",
        "    class_mode='categorical', batch_size=50, shuffle=False,\n",
        "    save_format='jpeg', subset='training')\n",
        "  \n",
        "  return data_gen, df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CxHlKnW5OdN"
      },
      "source": [
        "def occlusion(model, X, y, img_num=10, patch_size=4):\n",
        "\n",
        "  # Load image from the test data\n",
        "  data_gen, df = load_dataset()\n",
        "  label_dict = { 0: 'no_damage', 1: 'damage'}\n",
        "  \n",
        "\n",
        "  num = img_num\n",
        "\n",
        "  if num>49:\n",
        "    num=1\n",
        "\n",
        "  # Get image \n",
        "  img = X[num]\n",
        "\n",
        "  # Get label\n",
        "  y_test = y[num]\n",
        "\n",
        "  # Get the patch size for occlusion\n",
        "  PATCH_SIZE = patch_size\n",
        "\n",
        "  # Get the loss of the model with the original image\n",
        "  loss = model.evaluate(img.reshape(-1,128,128,3), y_test.reshape(-1,1), verbose=0)\n",
        "\n",
        "  # Define a numpy array to store the loss differences\n",
        "  loss_map = np.zeros((img.shape[0], img.shape[1]))\n",
        "  \n",
        "  #test\n",
        "  pat = apply_grey_patch(img, 30, 30, 30)\n",
        "  #  pat = apply_grey_patch(pat, 90, 0, 60)\n",
        "  fig, ax = plt.subplots(1,1)\n",
        "  ax.imshow(pat)\n",
        "  #print(pat)\n",
        "\n",
        "  step = 5\n",
        "  # Iterate the patch over the entire image\n",
        "  for top_left_x in range(0, img.shape[0], step):\n",
        "\n",
        "    for top_left_y in range(0, img.shape[1], step):\n",
        "        \n",
        "      # Initialise a new patched image\n",
        "      patched_image = apply_grey_patch(img, top_left_x, top_left_y, PATCH_SIZE)\n",
        "\n",
        "      # Get the loss of the model for each patched version\n",
        "      result = model.evaluate(patched_image.reshape(-1,128,128,3), y_test.reshape(-1,1), verbose=0)\n",
        "\n",
        "      # Get the loss_map of the plot by computing the difference in loss from the original version to the patched value\n",
        "      loss_map[top_left_y:top_left_y + PATCH_SIZE, top_left_x:top_left_x + PATCH_SIZE] += loss[0] - result[0]\n",
        "  # print(loss_map.shape)\n",
        "\n",
        "  # Get the predicted label \n",
        "  y_prob = model.predict(img.reshape(-1,128,128,3))\n",
        "  y_pred = label_dict[1 if y_prob >= 0.5 else 0]\n",
        "  \n",
        "\n",
        "\n",
        "  # Get true label\t\n",
        "  y_true = label_dict[y_test]\n",
        "\n",
        "  \n",
        "  # print(model.evaluate(pat.reshape(-1,128,128,3), y_test.reshape(-1,1), verbose=0))\n",
        "  # print(model.predict(pat.reshape(-1,128,128,3)))\n",
        "  # print(loss_map.shape)\n",
        "\n",
        "  # Plot the original image along with the difference in loss as a heatmap\n",
        "  fig, ax = plt.subplots(1,2, figsize=(15,15))\n",
        "  plt.figure(num=None, figsize=(8, 6), dpi=100, facecolor='w', edgecolor='k')\n",
        "  ax[0].imshow(img)\n",
        "  ax[1].imshow(img, cmap='gray')\n",
        "  im = ax[1].imshow(-loss_map, cmap='Reds', alpha=0.5)\n",
        "  fig.colorbar(im,fraction=0.05)\n",
        "  ax[0].set_title(\"True Label: \"+y_true.upper(), fontsize=15)\n",
        "  ax[1].set_title(\"Predicted label with patch size \"+str(PATCH_SIZE)+\": \"+y_pred.upper(), fontsize=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gncCn2xJC_CZ"
      },
      "source": [
        "img_num = 23\n",
        "patch_size = 30\n",
        "\n",
        "occlusion(model5, X_train, y_train, img_num , patch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-2_6lZU6hAE"
      },
      "source": [
        "# 集成模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd_QNR5Q_OXB"
      },
      "source": [
        "basic_classicfier = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bB0TsX_cHsDR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "ef8716d9-3644-4ed7-c36f-38dacde2a753"
      },
      "source": [
        "  index = np.linspace(0,9999,10000, dtype = np.int)\n",
        "  index = shuffle(index)\n",
        "  new_X_train = []\n",
        "  new_y_train = []\n",
        "  for j in index:\n",
        "    new_X_train.append(X_train[j])\n",
        "    new_y_train.append(y_train[j])\n",
        "  new_X_train = np.array(new_X_train)\n",
        "  new_y_train = np.array(new_y_train)\n",
        "  # VGG16 TEST MODEL\n",
        "  weight_decay = 0.0005\n",
        "  nb_epoch=20\n",
        "  batch_size=32"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-80ffa0c473db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnew_y_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mnew_X_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mnew_y_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnew_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 2028 is out of bounds for axis 0 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKw9pW_i9VBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78a8451e-19ae-43ce-c87e-7e1c81d1a882"
      },
      "source": [
        "# Function of AlexNet\n",
        "def Alexnet():\n",
        "  model_alexnet_1 = Sequential()  \n",
        "  model_alexnet_1.add(Conv2D(96,(5,5),strides=(4,4),input_shape=input_shape,padding='valid',activation='relu',kernel_initializer='uniform'))  \n",
        "  model_alexnet_1.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))  \n",
        "  model_alexnet_1.add(Conv2D(256,(5,5),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
        "  model_alexnet_1.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))  \n",
        "  model_alexnet_1.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
        "  model_alexnet_1.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
        "  model_alexnet_1.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))  \n",
        "  model_alexnet_1.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))  \n",
        "  model_alexnet_1.add(Flatten())  \n",
        "  model_alexnet_1.add(Dense(1024,activation='relu'))  \n",
        "  model_alexnet_1.add(Dropout(0.5))  \n",
        "  model_alexnet_1.add(Dense(1024,activation='relu'))  \n",
        "  model_alexnet_1.add(Dropout(0.5))  \n",
        "  model_alexnet_1.add(Dense(1,activation='sigmoid'))  \n",
        "  sgd = keras.optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n",
        "  model_alexnet_1.compile(loss=keras.losses.binary_crossentropy,optimizer= 'adam',metrics=['accuracy'])  \n",
        "  model_alexnet_1.summary()  \n",
        "\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2)\n",
        "  model_alexnet_1.fit(new_X_train, new_y_train, epochs=nb_epoch, batch_size=batch_size, validation_split=0.2, verbose=1, callbacks=[early_stopping])\n",
        "\n",
        "  basic_classicfier.append(model_alexnet_1)\n",
        "Alexnet()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_47 (Conv2D)           (None, 31, 31, 96)        7296      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 15, 15, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 15, 15, 256)       614656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 7, 7, 384)         885120    \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 7, 7, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 7, 7, 256)         884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1024)              2360320   \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 7,130,497\n",
            "Trainable params: 7,130,497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.2826 - accuracy: 0.9932 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 3s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 3s 14ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 3s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 3s 14ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 3s 14ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSHEWBKU-ae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b86c709-e2c6-4833-f365-50ce66301461"
      },
      "source": [
        "def vgg16():\n",
        "  # VGG16 TEST MODEL\n",
        "  weight_decay = 0.0005\n",
        "  nb_epoch=100\n",
        "  batch_size=32\n",
        "    \n",
        "  #layer1 32*32*3\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, (3, 3), padding='same',\n",
        "  input_shape=input_shape,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.3))\n",
        "  #layer2 32*32*64\n",
        "  model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  #layer3 16*16*64\n",
        "  model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "  #layer4 16*16*128\n",
        "  model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  #layer5 8*8*128\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "  #layer6 8*8*256\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "  #layer7 8*8*256\n",
        "  model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  #layer8 4*4*256\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "  #layer9 4*4*512\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "  #layer10 4*4*512\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  #layer11 2*2*512\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "  #layer12 2*2*512\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "  #layer13 2*2*512\n",
        "  model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.5))\n",
        "  #layer14 1*1*512\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  #layer15 512\n",
        "  model.add(Dense(512,kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  #layer16 512\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(1))\n",
        "  model.add(Activation('sigmoid'))\n",
        "  # 10\n",
        "    \n",
        "  sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2)\n",
        "  model.fit(new_X_train, new_y_train, epochs=nb_epoch, batch_size=batch_size, validation_split=0.2, verbose=1, callbacks=[early_stopping])\n",
        "  basic_classicfier.append(model)\n",
        "vgg16()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 57s 197ms/step - loss: 3.3971 - accuracy: 0.7720 - val_loss: 2.6951 - val_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 48s 193ms/step - loss: 2.5904 - accuracy: 0.9979 - val_loss: 2.1799 - val_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 2.0582 - accuracy: 0.9996 - val_loss: 1.6935 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 1.5866 - accuracy: 0.9996 - val_loss: 1.2795 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 1.1929 - accuracy: 0.9998 - val_loss: 0.9629 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 49s 194ms/step - loss: 0.8842 - accuracy: 1.0000 - val_loss: 0.6978 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 0.6485 - accuracy: 1.0000 - val_loss: 0.5107 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 0.4737 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 0.3493 - accuracy: 1.0000 - val_loss: 0.2780 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 0.2583 - accuracy: 1.0000 - val_loss: 0.2071 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 0.1952 - accuracy: 1.0000 - val_loss: 0.1557 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 0.1449 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 0.1091 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 0.0869 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 0.1398 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 0.1113 - accuracy: 0.9995 - val_loss: 0.0537 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 0.4291 - accuracy: 0.9996 - val_loss: 0.3640 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 0.2607 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 0.0377 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 48s 194ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 48s 193ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 48s 193ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 48s 193ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 48s 193ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 48s 193ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 48s 192ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 48s 192ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 48s 192ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 48s 192ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 47s 189ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.2028e-04 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 47s 188ms/step - loss: 8.8210e-04 - accuracy: 1.0000 - val_loss: 7.7640e-04 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 47s 188ms/step - loss: 7.4646e-04 - accuracy: 1.0000 - val_loss: 6.6215e-04 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 47s 188ms/step - loss: 6.3773e-04 - accuracy: 1.0000 - val_loss: 5.6796e-04 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 47s 187ms/step - loss: 5.4737e-04 - accuracy: 1.0000 - val_loss: 4.8780e-04 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 47s 187ms/step - loss: 4.7000e-04 - accuracy: 1.0000 - val_loss: 4.1797e-04 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 47s 186ms/step - loss: 4.0233e-04 - accuracy: 1.0000 - val_loss: 3.5630e-04 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 47s 186ms/step - loss: 3.4242e-04 - accuracy: 1.0000 - val_loss: 3.0154e-04 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 46s 186ms/step - loss: 2.8924e-04 - accuracy: 1.0000 - val_loss: 2.5299e-04 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 46s 186ms/step - loss: 2.4212e-04 - accuracy: 1.0000 - val_loss: 2.1019e-04 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 46s 186ms/step - loss: 2.0071e-04 - accuracy: 1.0000 - val_loss: 1.7281e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "109/250 [============>.................] - ETA: 24s - loss: 1.6933e-04 - accuracy: 1.0000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-8df85db3ea6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0mbasic_classicfier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mvgg16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-8df85db3ea6f>\u001b[0m in \u001b[0;36mvgg16\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m   \u001b[0mbasic_classicfier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "29iQLoxHPz94",
        "outputId": "7309c7c5-dd26-448a-85fb-24d39b987ae3"
      },
      "source": [
        "basic_classicfier.append(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-96d45a210b0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbasic_classicfier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLwL2AzZ_vmv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f527381-8145-48b7-bb68-cc407e08f08c"
      },
      "source": [
        "# Xception function\n",
        "\n",
        "import os  \n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
        "\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Conv2D, Dense, BatchNormalization, Activation\n",
        "from keras.layers import GlobalAveragePooling2D, MaxPooling2D, add\n",
        "from keras.models import Model\n",
        "from keras.layers import SeparableConv2D\n",
        "\n",
        "from keras import optimizers,regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.initializers import he_normal\n",
        "from keras.callbacks import LearningRateScheduler, TensorBoard, ModelCheckpoint\n",
        "\n",
        "batch_size         = 32         # 64 or 32 or other\n",
        "epochs             = 8\n",
        "\n",
        "# 36 convolutional layers are structured into 14 modules\n",
        "def entryflow(x,params,top=False):\n",
        "    # modules 2-4,13\n",
        "    # params is (3,)\n",
        "    # top = true means module 2, don't use relu\n",
        "    residual = Conv2D(params[0], (1, 1), strides=(2, 2),padding='same')(x)\n",
        "    residual = BatchNormalization()(residual)\n",
        "    if top:\n",
        "        x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params[1], (2, 2),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params[2], (2, 2),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2),padding='same')(x)\n",
        "    x = add([x, residual])\n",
        "    return x\n",
        "\n",
        "def middleflow(x,params):\n",
        "    # modules 5-12, params is int\n",
        "    residual = x\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params, (2, 2),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params, (2, 2),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params, (2, 2),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = add([x, residual])\n",
        "    return x\n",
        "\n",
        "def exitflow(x,params):\n",
        "    # modules 14 , params is (2,)\n",
        "    x = SeparableConv2D(params[0], (2, 2),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = SeparableConv2D(params[1], (2, 2),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)   \n",
        "    return x\n",
        "\n",
        "def xception(img_input,shallow=False, classes=1):\n",
        "    # modules 1\n",
        "    x = Conv2D(32,(2, 2),strides=(2, 2),padding='same')(img_input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(64, (2, 2),strides=(1,1),padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    # module 2\n",
        "    x = entryflow(x,(32,32,32),top=True)\n",
        "    # module 3-4\n",
        "    x = entryflow(x,(32,32,32))\n",
        "    x = entryflow(x,(32,32,32))\n",
        "    # module 5-12\n",
        "    for _ in range(8):\n",
        "        x = middleflow(x,32)\n",
        "    # module 13\n",
        "    x = entryflow(x,(128,128,128))\n",
        "    # module 14\n",
        "    x = exitflow(x,(128,128))\n",
        "    # output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(classes, activation='sigmoid')(x)\n",
        "    return x\n",
        "img_input=Input(shape=(128,128,3))\n",
        "output = xception(img_input)\n",
        "model_Xcep=Model(img_input,output)\n",
        "model_Xcep.summary()\n",
        "\n",
        "model_Xcep.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2)\n",
        "model_Xcep.fit(new_X_train, new_y_train, epochs=nb_epoch, batch_size=batch_size, validation_split=0.2, verbose=1, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 32)   416         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 64, 64, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 64, 64, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 64)   8256        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 64, 64, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64, 64, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d (SeparableConv (None, 64, 64, 32)   2336        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64, 64, 32)   128         separable_conv2d[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_1 (SeparableCo (None, 64, 64, 32)   1184        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 64, 32)   128         separable_conv2d_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 32)   2080        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 32)   0           max_pooling2d_3[0][0]            \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_2 (SeparableCo (None, 32, 32, 32)   1184        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 32)   128         separable_conv2d_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 32)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_3 (SeparableCo (None, 32, 32, 32)   1184        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 32)   128         separable_conv2d_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 32)   1056        add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 16, 16, 32)   0           max_pooling2d_4[0][0]            \n",
            "                                                                 batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_4 (SeparableCo (None, 16, 16, 32)   1184        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         separable_conv2d_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 32)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_5 (SeparableCo (None, 16, 16, 32)   1184        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         separable_conv2d_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 8, 8, 32)     1056        add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 32)     0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 8, 8, 32)     128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 8, 8, 32)     0           max_pooling2d_5[0][0]            \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 8, 8, 32)     0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_6 (SeparableCo (None, 8, 8, 32)     1184        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 8, 8, 32)     0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_7 (SeparableCo (None, 8, 8, 32)     1184        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 8, 8, 32)     0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_8 (SeparableCo (None, 8, 8, 32)     1184        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 8, 8, 32)     0           batch_normalization_13[0][0]     \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 8, 8, 32)     0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_9 (SeparableCo (None, 8, 8, 32)     1184        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_9[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 8, 8, 32)     0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_10 (SeparableC (None, 8, 8, 32)     1184        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_10[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 8, 8, 32)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_11 (SeparableC (None, 8, 8, 32)     1184        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_11[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 8, 8, 32)     0           batch_normalization_16[0][0]     \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 8, 8, 32)     0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_12 (SeparableC (None, 8, 8, 32)     1184        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_12[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 8, 32)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_13 (SeparableC (None, 8, 8, 32)     1184        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_13[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 32)     0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_14 (SeparableC (None, 8, 8, 32)     1184        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_14[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 8, 8, 32)     0           batch_normalization_19[0][0]     \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 32)     0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_15 (SeparableC (None, 8, 8, 32)     1184        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_15[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 32)     0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_16 (SeparableC (None, 8, 8, 32)     1184        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_16[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 32)     0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_17 (SeparableC (None, 8, 8, 32)     1184        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_17[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 32)     0           batch_normalization_22[0][0]     \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 32)     0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_18 (SeparableC (None, 8, 8, 32)     1184        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_18[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 32)     0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_19 (SeparableC (None, 8, 8, 32)     1184        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_19[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 8, 8, 32)     0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_20 (SeparableC (None, 8, 8, 32)     1184        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_20[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 32)     0           batch_normalization_25[0][0]     \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 32)     0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_21 (SeparableC (None, 8, 8, 32)     1184        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_21[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 32)     0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_22 (SeparableC (None, 8, 8, 32)     1184        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_22[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 8, 8, 32)     0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_23 (SeparableC (None, 8, 8, 32)     1184        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 32)     0           batch_normalization_28[0][0]     \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 8, 8, 32)     0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_24 (SeparableC (None, 8, 8, 32)     1184        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_24[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 8, 8, 32)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_25 (SeparableC (None, 8, 8, 32)     1184        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_25[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 32)     0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_26 (SeparableC (None, 8, 8, 32)     1184        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_26[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 32)     0           batch_normalization_31[0][0]     \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 32)     0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_27 (SeparableC (None, 8, 8, 32)     1184        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_27[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 32)     0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_28 (SeparableC (None, 8, 8, 32)     1184        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_28[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 32)     0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_29 (SeparableC (None, 8, 8, 32)     1184        activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 32)     128         separable_conv2d_29[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 32)     0           batch_normalization_34[0][0]     \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_30 (SeparableC (None, 8, 8, 128)    4352        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_30[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_31 (SeparableC (None, 8, 8, 128)    17024       activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 128)    512         separable_conv2d_31[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 4, 4, 128)    4224        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 4, 4, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 4, 4, 128)    512         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 4, 4, 128)    0           max_pooling2d_6[0][0]            \n",
            "                                                                 batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_32 (SeparableC (None, 4, 4, 128)    17024       add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 4, 4, 128)    512         separable_conv2d_32[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 4, 4, 128)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "separable_conv2d_33 (SeparableC (None, 4, 4, 128)    17024       activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 4, 4, 128)    512         separable_conv2d_33[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 4, 4, 128)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 128)          0           activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            129         global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 116,481\n",
            "Trainable params: 112,897\n",
            "Non-trainable params: 3,584\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-993dc647f23b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0mmodel_Xcep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mmodel_Xcep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'new_X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9LqA_Zh6ldP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f2a8d695-e94f-4238-c07e-1d93de5764c7"
      },
      "source": [
        "# sampleing & data process\n",
        "# train the basic classicfier in odd number\n",
        "for i in range(3):\n",
        "  # generate the basic training data of bagging, using shuffle to simulate the process\n",
        "  # of generating the random dataset which the size of it equals to the original one.\n",
        "  index = np.linspace(0,9999,10000, dtype = np.int)\n",
        "  index = shuffle(index)\n",
        "  new_X_train = []\n",
        "  new_y_train = []\n",
        "  for j in index:\n",
        "    new_X_train.append(X_train[i])\n",
        "    new_y_train.append(y_train[i])\n",
        "  new_X_train = np.array(new_X_train)\n",
        "  new_y_train = np.array(new_y_train)\n",
        "  # VGG16 TEST MODEL\n",
        "  weight_decay = 0.0005\n",
        "  nb_epoch=20\n",
        "  batch_size=32\n",
        "  # The Defination of Model\n",
        "  if i== 0:\n",
        "    Alexnet()\n",
        "  if i==1:\n",
        "    vgg16()\n",
        "  if i==2:\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=2)\n",
        "    model_Xcep.fit(new_X_train, new_y_train, epochs=nb_epoch, batch_size=batch_size, validation_split=0.2, verbose=1, callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_29 (Conv2D)           (None, 31, 31, 96)        7296      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 15, 15, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 15, 15, 256)       614656    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 7, 7, 384)         885120    \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 7, 7, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 7, 7, 256)         884992    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1024)              2360320   \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 7,130,497\n",
            "Trainable params: 7,130,497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "250/250 [==============================] - 4s 14ms/step - loss: 0.2358 - accuracy: 0.9947 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "250/250 [==============================] - 3s 13ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "250/250 [==============================] - 3s 14ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "250/250 [==============================] - 3s 14ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "250/250 [==============================] - 3s 14ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "250/250 [==============================] - 3s 14ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-937c73980e26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mAlexnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mvgg16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-54e62274fb86>\u001b[0m in \u001b[0;36mvgg16\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m   \u001b[0mbasic_classicfier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'early_stopping' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rarflK2E63dO"
      },
      "source": [
        "# the process of bagging\n",
        "# fit each model using the original data\n",
        "res_pre = []\n",
        "for w in basic_classicfier:\n",
        "  pre_res = w.predict_classes(X_test)\n",
        "  res_pre.append(pre_res)\n",
        "# the process of voting\n",
        "right_count = 0\n",
        "new_res = []\n",
        "# presicion and recall\n",
        "tp = 0\n",
        "fp = 0\n",
        "tn = 0\n",
        "fn = 0\n",
        "for i in range(2000):\n",
        "  res_tmp = []\n",
        "  for item in res_pre:\n",
        "    res_tmp.append(item[i])\n",
        "  res_val_0 = res_tmp.count(0)\n",
        "  res_val_1 = res_tmp.count(1)\n",
        "  if res_val_0 > res_val_1:\n",
        "    res_val = 0\n",
        "  else:\n",
        "    res_val = 1\n",
        "  new_res.append(res_val)\n",
        "  if res_val == y_test[i]:\n",
        "    right_count += 1\n",
        "    if res_val == 1:\n",
        "      tp += 1\n",
        "    if res_val == 0:\n",
        "      tn += 1\n",
        "  else:\n",
        "    if res_val == 1:\n",
        "      fp += 1\n",
        "    if res_val == 0:\n",
        "      fn += 1\n",
        "recall = tp/(tp+fn)\n",
        "precise = tp/(tp+fp)\n",
        "bagging_accuracy = right_count/2000*100\n",
        "print(\"accuracy: \" + str(bagging_accuracy) + \"%\")\n",
        "print(\"recall: \" + str(recall) + \"%\")\n",
        "print(\"precise: \" + str(precise) + \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3YW3lTM636W"
      },
      "source": [
        "# the process of bagging\n",
        "# fit each model using the original data\n",
        "res_pre = []\n",
        "for w in basic_classicfier:\n",
        "  pre_res = w.predict_classes(X_test_unbal)\n",
        "  res_pre.append(pre_res)\n",
        "# the process of voting\n",
        "right_count = 0\n",
        "new_res = []\n",
        "# presicion and recall\n",
        "tp = 0\n",
        "fp = 0\n",
        "tn = 0\n",
        "fn = 0\n",
        "for i in range(2000):\n",
        "  res_tmp = []\n",
        "  for item in res_pre:\n",
        "    res_tmp.append(item[i])\n",
        "  res_val_0 = res_tmp.count(0)\n",
        "  res_val_1 = res_tmp.count(1)\n",
        "  if res_val_0 > res_val_1:\n",
        "    res_val = 0\n",
        "  else:\n",
        "    res_val = 1\n",
        "  new_res.append(res_val)\n",
        "  if res_val == y_test_unbal[i]:\n",
        "    right_count += 1\n",
        "    if res_val == 1:\n",
        "      tp += 1\n",
        "    if res_val == 0:\n",
        "      tn += 1\n",
        "  else:\n",
        "    if res_val == 1:\n",
        "      fp += 1\n",
        "    if res_val == 0:\n",
        "      fn += 1\n",
        "recall = tp/(tp+fn)\n",
        "precise = tp/(tp+fp)\n",
        "bagging_accuracy = right_count/2000*100\n",
        "print(\"accuracy: \" + str(bagging_accuracy) + \"%\")\n",
        "print(\"recall: \" + str(recall) + \"%\")\n",
        "print(\"precise: \" + str(precise) + \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}